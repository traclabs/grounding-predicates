{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 2: Run model\n",
    "\n",
    "Script for loading a hdf5 file and running the trained model in one of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(sys.path[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "os.environ[\"PYGAME_HIDE_SUPPORT_PROMPT\"] = \"1\"\n",
    "import yaml\n",
    "\n",
    "import pygame\n",
    "pygame.init()\n",
    "\n",
    "import symbolic\n",
    "from config import EnvironmentPaths\n",
    "\n",
    "paths = EnvironmentPaths(environment=\"gridworld\")\n",
    "pddl = symbolic.Pddl(str(paths.domain_pddl), str(paths.problem_pddl))\n",
    "\n",
    "with open(paths.env / \"config.yaml\") as f:\n",
    "    config = yaml.full_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test some PDDL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State index: 197\n",
      "Set problem\n",
      "Dset idx\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f6a252e38e0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-fcc346f117a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Set up network\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/grounding-predicates/gpred/problem.py\u001b[0m in \u001b[0;36mset_data_batch\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBatch\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_partial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \"\"\"\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;31m# ([-32, 5, H, W], [-32, 3, 5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "from gpred import dnf_utils\n",
    "from gpred import dataset\n",
    "import torchvision\n",
    "import torch\n",
    "from gpred import model\n",
    "from gpred import problem\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "n = pddl.state_index\n",
    "print(\"State index: {}\".format(len(n)))\n",
    "\n",
    "idx_static = dnf_utils.get_static_props(pddl)\n",
    "\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cuda:0')\n",
    "model_type = \"resnet\"\n",
    "dataset = \"dataset.hdf5\"\n",
    "\n",
    "\n",
    "problem = problem.GridworldPredicateClassification(pddl,\n",
    "                                          device,\n",
    "                                          paths.data,\n",
    "                                          dataset,\n",
    "                                          ground_truth=False,\n",
    "                                          use_weighted_ce=False)\n",
    "\n",
    "dset =  DataLoader(problem.val_set, batch_size=1,\n",
    "                shuffle=False,\n",
    "                pin_memory=True),\n",
    "#                collate_fn=train_set.collate_fn)\n",
    "\n",
    "# Set problem\n",
    "print(\"Set problem\")\n",
    "idx = 0\n",
    "\n",
    "print(\"Dset idx\")\n",
    "b = dset[idx]\n",
    "print(b)\n",
    "problem.set_data_batch(idx_data)\n",
    "\n",
    "print(\"Set up network\")\n",
    "network = model.PredicateNet(dim_input = problem.dim_x, \n",
    "                           num_predicates = problem.dim_y, \n",
    "                           num_args = 3, \n",
    "                           model = model_type, \n",
    "                           freeze_features = True).to(device)\n",
    "\n",
    "\n",
    "#            for idx_batch, data in enumerate(train_loop):\n",
    "#                # Forward pass\n",
    "#                problem.set_data_batch(data)\n",
    "\n",
    "\n",
    "# Load model parameters\n",
    "print(\"Loading network\")\n",
    "aa = torch.load(\"/home/ana/Desktop/grounding-predicates/models/gridworld/exp-1/Feb24_17-34-37/model.pth\")\n",
    "print(\"AA type:\")\n",
    "print(type(aa))\n",
    "print(aa.keys())\n",
    "network.load_state_dict(aa[\"model_state_dict\"])\n",
    "print(\"Loaded fine!\")\n",
    "\n",
    "print(\"Try to run\")\n",
    "y_predict = network(problem.get_x())\n",
    "print(\"Run?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "#for i in tqdm.tqdm(range(int(9e6))):\n",
    "#    pass\n",
    "\n",
    "\n",
    "import h5py\n",
    "import pathlib\n",
    "\n",
    "dset = \"dataset.hdf5\"\n",
    "\n",
    "\n",
    "f = h5py.File(paths.data / dset, \"r\")\n",
    "      \n",
    "# Get dsets\n",
    "action_dset = f[\"actions\"]\n",
    "print(\"Action 0: \")\n",
    "print(action_dset[0])\n",
    "  \n",
    "#actions = set(tqdm.tqdm(action_dset))      \n",
    "actions = [action.decode(\"utf-8\") for action in set(f[\"actions\"])]\n",
    "actions = set(tqdm.tqdm(actions))\n",
    "\n",
    "max_num_conjunctions = dnf_utils.compute_max_num_conjunctions(pddl, actions)\n",
    "print(\"Yay!\")\n",
    "\n",
    "#dataset = dataset.Dataset(pddl, path=paths.data, dataset = \"dataset.hdf5\", split= (0.0, 0.5), max_size=None, \n",
    "#                        transform = torchvision.transforms.ToTensor(), max_num_conjunctions=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions useful for loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define state generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from env.gridworld import propositions\n",
    "from env.gridworld.dataset import LogDatabase\n",
    "from env.gridworld.propositions import ArgumentTypeError, PropositionValueError\n",
    "from env.gridworld.world import World\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define IO functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Stdout:\n",
    "    \"\"\"Dummy class for logging to stdout.\"\"\"\n",
    "    def write(self, message):\n",
    "        print(message)\n",
    "\n",
    "def save_images(log, img_pre, img_post):\n",
    "    \"\"\"Save pre and post images with the current log key.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        img_pre (np.ndarray): Pre image.\n",
    "        img_post (np.ndarray): Post image.\n",
    "    \"\"\"\n",
    "    plt.imsave(log.path_images / f\"{log.key}_pre.png\", img_pre)\n",
    "    plt.imsave(log.path_images / f\"{log.key}_post.png\", img_post)\n",
    "    \n",
    "def load_images(log, key):\n",
    "    \"\"\"Load pre and post images from the given log key.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        key (int): Log to load.\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): Pair of pre, post images\n",
    "    \"\"\"\n",
    "    img_pre = plt.imread(log.path_images / f\"{key}_pre.png\")\n",
    "    img_post = plt.imread(log.path_images / f\"{key}_post.png\")\n",
    "    return (img_pre, img_post)\n",
    "\n",
    "def render_images(img_pre, img_post):\n",
    "    \"\"\"Render pre and post images side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        img_pre (np.ndarray): Pre image.\n",
    "        img_post (np.ndarray): Post image.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.imshow(img_pre, interpolation='none')\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.imshow(img_post, interpolation='none')\n",
    "    plt.show()\n",
    "\n",
    "def save_variables(log, pddl, config, action_call, conj, debug: bool = True):\n",
    "    \"\"\"Save the given variables, along with the current random seed, at the current log key.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        pddl (symbolic.Pddl): Pddl instance.\n",
    "        config (dict): World config.\n",
    "        action_call (str): Action call.\n",
    "        conj (symbolic.PartialState): Precondition dnf conjunction.\n",
    "        debug: Save all variables if true, otherwise save only necessary variables.\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        log.save({\n",
    "            \"pddl\": pddl,\n",
    "            \"config\": config,\n",
    "            \"action_call\": action_call,\n",
    "            \"conj\": conj,\n",
    "            \"state_random\": random.getstate(),\n",
    "            \"state_np_random\": np.random.get_state(),\n",
    "        })\n",
    "    else:\n",
    "        log.save({\n",
    "            \"action_call\": action_call,\n",
    "        })\n",
    "\n",
    "def load_variables(log, key, verbose=True):\n",
    "    \"\"\"Load the saved variables, along with the saved random seed, at the given log key.\n",
    "    \n",
    "    Optionally print the saved log.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        key (int): Log to load.\n",
    "        verbose (bool, optional): Whether to print the log (default True).\n",
    "    Returns:\n",
    "        (pddl, config, action_call, conj): Tuple of saved variables.\n",
    "    \"\"\"\n",
    "    # Load variables\n",
    "    variables = log.load(key, verbose=verbose)\n",
    "    pddl = variables[\"pddl\"]\n",
    "    config = variables[\"config\"]\n",
    "    action_call = variables[\"action_call\"]\n",
    "    conj = variables[\"conj\"]\n",
    "    \n",
    "    # Set random state\n",
    "    random.setstate(variables[\"state_random\"])\n",
    "    np.random.set_state(variables[\"state_np_random\"])\n",
    "    \n",
    "    return pddl, config, action_call, conj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "Take logs, images, and variables from `data/gridworld` and convert them to vector format in `data/gridworld/dataset.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 3317 . Action: b'pick-fail(chest_key, room_b)'\n",
      "Boxes pre: \n",
      "[[ 40.  20.  60.  40.]\n",
      " [ 40.  20.  60.  40.]\n",
      " [  0.   0. 120. 220.]\n",
      " [100.   0. 220. 220.]\n",
      " [100.  80. 120. 100.]\n",
      " [ nan  nan  nan  nan]\n",
      " [ 20.  20.  40.  40.]\n",
      " [140.  60. 160.  80.]\n",
      " [ nan  nan  nan  nan]]\n",
      "Boxes post: \n",
      "[[ 40.  20.  60.  40.]\n",
      " [ 40.  20.  60.  40.]\n",
      " [  0.   0. 120. 220.]\n",
      " [100.   0. 220. 220.]\n",
      " [100.  80. 120. 100.]\n",
      " [ nan  nan  nan  nan]\n",
      " [ 20.  20.  40.  40.]\n",
      " [140.  60. 160.  80.]\n",
      " [ nan  nan  nan  nan]]\n",
      "S pre\n",
      "[False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False  True  True False False False False False\n",
      " False False False False False False False False False False False  True\n",
      " False False False False False False False False False  True False False\n",
      " False False False False False False False False False False False False\n",
      " False  True  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-47d4ee1484cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Test with an idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2003\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mshow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#log.publish_dataset(\"dataset.hdf5\", tqdm=tqdm.notebook.tqdm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-47d4ee1484cd>\u001b[0m in \u001b[0;36mshow_data\u001b[0;34m(path, dataset, idx)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mimg_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_post_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from env.gridworld.dataset import LogDatabase\n",
    "import tqdm.notebook\n",
    "import h5py\n",
    "import pathlib\n",
    "\n",
    "# Create log database in case previous cell was not run\n",
    "log = LogDatabase(path=paths.data)\n",
    "\n",
    "path = paths.data\n",
    "dataset = \"dataset.hdf5\"\n",
    "\n",
    "def show_data(path, dataset, idx):\n",
    "\n",
    "    with h5py.File(pathlib.Path(path) / dataset, \"r\") as f:\n",
    "        #print(f.keys())\n",
    "        \n",
    "        # Get dsets\n",
    "        img_pre_dset = f[\"img_pre\"]\n",
    "        img_post_dset = f[\"img_post\"]\n",
    "        key_dset = f[\"keys\"]\n",
    "        action_dset = f[\"actions\"]\n",
    "        boxes_pre_dset = f[\"boxes_pre\"]\n",
    "        boxes_post_dset = f[\"boxes_post\"]\n",
    "        s_post_dset = f[\"s_post\"]\n",
    "        s_pre_dset = f[\"s_pre\"]\n",
    "        \n",
    "        #print(img_pre_dset.shape)\n",
    "        #print(key_dset.shape)\n",
    "    \n",
    "        print(\"Key: {} . Action: {}\".format(key_dset[idx], action_dset[idx]))\n",
    "        print(\"Boxes pre: \")\n",
    "        print(boxes_pre_dset[idx])\n",
    "        \n",
    "        print(\"Boxes post: \")\n",
    "        print(boxes_post_dset[idx])\n",
    "        \n",
    "        print(\"S pre\")\n",
    "        print(s_pre_dset[idx])\n",
    "        \n",
    "        img_pre = img_pre_dset[idx]\n",
    "        img_post = img_post_dset[idx]\n",
    "        \n",
    "        fig = plt.figure(figsize=(14,7))\n",
    "        ax1 = plt.subplot(121)\n",
    "        ax1.imshow(img_pre, interpolation='none')\n",
    "        ax2 = plt.subplot(122)\n",
    "        ax2.imshow(img_post, interpolation='none')\n",
    "        plt.show()\n",
    "                \n",
    "        # Save\n",
    "        log.key = idx\n",
    "        save_images(log, img_pre, img_post)\n",
    "            \n",
    "# Test with an idx    \n",
    "idx = 2003\n",
    "show_data(path, dataset, idx)\n",
    "\n",
    "#log.publish_dataset(\"dataset.hdf5\", tqdm=tqdm.notebook.tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
